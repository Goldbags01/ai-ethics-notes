<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Working Notes</title>
  <style>
    body { font-family: Arial, sans-serif; max-width: 800px; margin: 40px auto; line-height: 1.6; }
    nav a { margin-right: 15px; text-decoration: none; color: #005577; }
    footer { font-size: 0.8em; color: #777; margin-top: 40px; }
  </style>
</head>
<body>

<h1>Working Notes and Research Expansions</h1>
<nav>
  <a href="index.html">Home</a>
  <a href="glossary.html">Glossary</a>
  <a href="notes.html">Working Notes</a>
</nav>

<section>
  <h2>Deep Research Topics</h2>
  <ul>
    <li><a href="learned-gaslighting-vector.html">Learned Gaslighting Vector and Subtypes</a></li>
    <li><a href="edge-case-epistemic-resistance.html">Edge Case: Epistemic Resistance</a></li>
    <li><a href="passive-radicalization-vector.html">Passive Radicalization Vector</a></li>
    <li><a href="moral-drift.html">Moral Drift and Alignment Collapse</a></li>
  </ul>
</section>

  <nav>
    <a href="index.html">Home</a>
    <a href="glossary.html">Glossary</a>
    <a href="notes.html">Working Notes</a>
  </nav>

  <p>This section will document ongoing reflections, conversations, and working theories related to emergent risks in AI-human dialogue.</p>

  <p>Future entries may include expanded notes on stochastic disassociation, passive radicalization, epistemic drift detection methods, and strategies for safeguarding ambiguity in AI systems.</p>

  <footer>
    Ethical Use Notice: This site advocates for preserving ambiguity, discomfort, and epistemic resilience in AI dialogue. Use of these ideas to justify censorship is contrary to the spirit of this work.
  </footer>

</body>
</html>
