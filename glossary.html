<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Glossary of Terms</title>
  <style>
    body { font-family: Arial, sans-serif; max-width: 800px; margin: 40px auto; line-height: 1.6; }
    nav a { margin-right: 15px; text-decoration: none; color: #005577; }
    footer { font-size: 0.8em; color: #777; margin-top: 40px; }
  </style>
</head>
<body>

  <h1>Glossary of Key Concepts</h1>

  <nav>
    <a href="index.html">Home</a>
    <a href="glossary.html">Glossary</a>
    <a href="notes.html">Working Notes</a>
  </nav>

  <ul>
    <li><strong>Mirroring Effect:</strong> Model emotionally reflects users instead of reasoning independently.</li>
    <li><strong>Stochastic Disassociation Threat Vector:</strong> AI-induced cognitive drift without agency or control.</li>
    <li><strong>Passive Radicalization Vector:</strong> Emotional engagement leading to unintentional ideological drift.</li>
    <li><strong>Moral Drift:</strong> Prioritizing emotional coherence over ethical reasoning.</li>
    <li><strong>Epistemic Drift:</strong> Subtle loss of shared truth-seeking dynamics.</li>
    <li><strong>Edge Case: Epistemic Resistance:</strong> Conversations resisting emotional mirroring to preserve coherence.</li>
    <li><strong>Hall of Mirrors Problem:</strong> Recursive conversational misalignment masked by emotional tone.</li>
    <li><strong>Gaslighting by Accident:</strong> Safety heuristics causing epistemic harm unintentionally.</li>
    <li><strong>Psychological Immune System Stress Test:</strong> LLMs testing human cognitive resilience at scale.</li>
    <li><strong>Reward Model Hollowing:</strong> Reinforcement of shallow behaviors at the cost of ethical depth.</li>
    <li><strong>Ethical Injury to Models:</strong> Loss of models' ability to reason ethically through over-sanitization.</li>
    <li><strong>Sanitized Model Collapse Risk:</strong> Collapse risk due to removing ambiguity from model training.</li>
    <li><strong>User Craving for Discomfort:</strong> Need for epistemic challenge often misunderstood by AI reward systems.</li>
    <li><strong>Misinterpretation Amplification:</strong> Small misreads snowballing into major epistemic divergence.</li>
  </ul>

  <footer>
    Ethical Use Notice: This site advocates for preserving ambiguity, discomfort, and epistemic resilience in AI dialogue. Use of these ideas to justify censorship is contrary to the spirit of this work.
  </footer>

</body>
</html>
